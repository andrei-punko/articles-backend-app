input {
  beats {
    port => 5000
    ssl  => false
    # TODO: still something wrong because have next warning in logs:
    # [WARN ][logstash.codecs.multiline] Received an event that has a different character encoding than you configured. {:text=>":\\xC3\\xC1]>\\u000EW
    # And messages not separated using Grok pattern because of that
    # BUT: it's actual on Win machine, on Linux it work properly
    # Created issue on that: https://github.com/andrei-punko/articles-backend-app/issues/2
  }
}

filter {
  # If log line contains tab character followed by 'at' then we will tag that entry as stacktrace
  if [message] =~ "\tat" {
    grok {
      match => ["message", "^(\tat)"]
      add_tag => ["stacktrace"]
    }
  }

  # Grokking Spring Boot's log. Next resources used as reference:
  # https://streamsets.com/documentation/datacollector/latest/help/datacollector/UserGuide/Apx-GrokPatterns/GrokPatterns_title.html
  # http://grokdebug.herokuapp.com/
  grok {
    match => [ "message",  "%{LOGLEVEL:level} %{YEAR}-%{MONTHNUM}-%{MONTHDAY} %{TIME} %{DATA:pid} \| %{JAVACLASS:class} \| %{GREEDYDATA:message}" ]
  }
}

output {
  # Print each event to stdout, useful for debugging. Should be commented out in production.
  # Enabling 'rubydebug' codec on the stdout output will make logstash
  # pretty-print the entire event as something similar to a JSON representation.
  stdout {
    codec => rubydebug
  }

  # Sending properly parsed log events to elasticsearch
  elasticsearch {
    hosts => [ "elasticsearch:9200" ]
    user => elastic
    password => yourstrongpasswordhere
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}